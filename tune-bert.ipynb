{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a698f022-91bb-4478-8be5-586bb49bcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e6cfa62-2566-4e0f-a562-0f975be10991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99af0df5-327e-43a0-b5fb-68f5784beb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd9505c-c93a-42c1-9114-0378ccda5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608a1501-b2a4-4f0a-9012-98a1b1cec76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc94bf6-f498-47ff-adb0-89ddaf8c5f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"STT2.tsv\", sep=\"\\t\", dtype=\"O\", header=None).rename(columns={0:\"text\", 1:\"target\"})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d68a4f-ea1f-46a8-bf1a-8685b8f0eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e727e9e5-fc46-4f01-9094-046f7e023492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text = list(train.text), list(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84b06f64-c453-47be-9442-4c7d873665f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = {\"train\":{\"text\":train_text}, \n",
    "#              \"test\":{\"text\":test_text}\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e29584-26a9-4335-812e-0690b62d4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea768133-3e52-4c97-a318-cb9d40abc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], \n",
    "                     max_length=512, \n",
    "                     add_special_tokens=True, \n",
    "                     truncation=True, \n",
    "                     return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ad442d-9290-45f4-ba64-65367b7d1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    block_size = 512 # block_size = tokenizer.model_max_length\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7121a45-0644-4b85-a378-724956f179e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(text):\n",
    "    data_dict = {\"text\":text}\n",
    "    dataset = Dataset.from_dict(data_dict)\n",
    "    token_datasets = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=\"text\")\n",
    "    lm_datasets = token_datasets.map(group_texts, batched=True, batch_size=64, num_proc=4)\n",
    "    return lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "735ebd5f-e311-405f-909d-f121305d50d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd11d65ee14858afcb86cd677be9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1d1c80e1c540f583c9e19855ffd1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = make_dataset(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a54efdf-1a2b-4365-9a00-65c242a8af8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b473db500529488cb201c84ab94a8367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2232b448c54bdda7a3e368a99cafdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataloader = make_dataset(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc54f35f-53d3-4bb4-8add-ea9bbc885565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "173def3a-7c9c-4f1d-b5d4-517171486337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rubert-tiny-finetuned\"\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_steps=30,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs=100,\n",
    "    resume_from_checkpoint=True,\n",
    "    report_to=[\"tensorboard\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1d6dbfe-c95e-4975-ad8f-2a0e22695e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=test_dataloader,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea92ad31-8fab-42f9-af24-0cf19e4ae4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 12:00, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.829000</td>\n",
       "      <td>4.119725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.925700</td>\n",
       "      <td>4.095912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.917900</td>\n",
       "      <td>4.070326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.037000</td>\n",
       "      <td>4.042260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.977000</td>\n",
       "      <td>4.055024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.968600</td>\n",
       "      <td>3.979620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.984600</td>\n",
       "      <td>4.038764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.978600</td>\n",
       "      <td>4.023667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.994800</td>\n",
       "      <td>4.042651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.036700</td>\n",
       "      <td>3.984468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.987000</td>\n",
       "      <td>4.018262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.973500</td>\n",
       "      <td>4.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.988200</td>\n",
       "      <td>3.981230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.945200</td>\n",
       "      <td>3.951817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.962900</td>\n",
       "      <td>3.992515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.929900</td>\n",
       "      <td>3.891410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.884500</td>\n",
       "      <td>3.871873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.898200</td>\n",
       "      <td>3.857836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.910400</td>\n",
       "      <td>3.962821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.867400</td>\n",
       "      <td>3.908790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.833400</td>\n",
       "      <td>3.899899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.881400</td>\n",
       "      <td>3.846342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.876600</td>\n",
       "      <td>3.979870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.786500</td>\n",
       "      <td>3.865577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.832400</td>\n",
       "      <td>3.804412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.774900</td>\n",
       "      <td>3.861199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.812300</td>\n",
       "      <td>3.801363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.800300</td>\n",
       "      <td>3.862368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3.735800</td>\n",
       "      <td>3.783103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.806400</td>\n",
       "      <td>3.864111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.723000</td>\n",
       "      <td>3.940212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.761300</td>\n",
       "      <td>3.931449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.667500</td>\n",
       "      <td>3.901340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.675800</td>\n",
       "      <td>3.869280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.713600</td>\n",
       "      <td>3.754571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.663400</td>\n",
       "      <td>3.811743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.699400</td>\n",
       "      <td>3.796015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.725000</td>\n",
       "      <td>3.770142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.671200</td>\n",
       "      <td>3.892286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.659100</td>\n",
       "      <td>3.771265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.650600</td>\n",
       "      <td>3.867197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.659300</td>\n",
       "      <td>3.789307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.640800</td>\n",
       "      <td>3.779631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3.635600</td>\n",
       "      <td>3.749434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.644100</td>\n",
       "      <td>3.753083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.637700</td>\n",
       "      <td>3.735484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.609700</td>\n",
       "      <td>3.713237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3.612900</td>\n",
       "      <td>3.791275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3.589900</td>\n",
       "      <td>3.754519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.603400</td>\n",
       "      <td>3.764764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>3.597800</td>\n",
       "      <td>3.759483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>3.568300</td>\n",
       "      <td>3.754772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>3.539100</td>\n",
       "      <td>3.675754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>3.587500</td>\n",
       "      <td>3.849362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.609300</td>\n",
       "      <td>3.650227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>3.612800</td>\n",
       "      <td>3.777676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>3.589700</td>\n",
       "      <td>3.770297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>3.596300</td>\n",
       "      <td>3.715438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>3.589800</td>\n",
       "      <td>3.750111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.545500</td>\n",
       "      <td>3.766210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>3.539200</td>\n",
       "      <td>3.694138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>3.533700</td>\n",
       "      <td>3.698529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>3.485700</td>\n",
       "      <td>3.688650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.533700</td>\n",
       "      <td>3.681035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.524400</td>\n",
       "      <td>3.812356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.544100</td>\n",
       "      <td>3.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>3.521000</td>\n",
       "      <td>3.725151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>3.532600</td>\n",
       "      <td>3.809826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>3.545200</td>\n",
       "      <td>3.730427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.493000</td>\n",
       "      <td>3.698493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.512700</td>\n",
       "      <td>3.672914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.464800</td>\n",
       "      <td>3.802269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.509900</td>\n",
       "      <td>3.743522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.523800</td>\n",
       "      <td>3.659510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.491600</td>\n",
       "      <td>3.708857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.451000</td>\n",
       "      <td>3.760131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.477300</td>\n",
       "      <td>3.650455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.499200</td>\n",
       "      <td>3.684494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.438800</td>\n",
       "      <td>3.666975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.502100</td>\n",
       "      <td>3.794978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.463600</td>\n",
       "      <td>3.703319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.494600</td>\n",
       "      <td>3.770132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.460300</td>\n",
       "      <td>3.746273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.512200</td>\n",
       "      <td>3.765030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.493800</td>\n",
       "      <td>3.674371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.468500</td>\n",
       "      <td>3.701384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.507300</td>\n",
       "      <td>3.696921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.505500</td>\n",
       "      <td>3.627380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.487500</td>\n",
       "      <td>3.610927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.469500</td>\n",
       "      <td>3.731582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.461800</td>\n",
       "      <td>3.664680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.488100</td>\n",
       "      <td>3.720043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.488000</td>\n",
       "      <td>3.675960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.432000</td>\n",
       "      <td>3.599599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.464000</td>\n",
       "      <td>3.692302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.474300</td>\n",
       "      <td>3.566351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>3.481600</td>\n",
       "      <td>3.737342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.475800</td>\n",
       "      <td>3.602893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>3.681993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.435600</td>\n",
       "      <td>3.587114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=3.6582925237019857, metrics={'train_runtime': 721.0544, 'train_samples_per_second': 32.73, 'train_steps_per_second': 4.161, 'total_flos': 180108602572800.0, 'train_loss': 3.6582925237019857, 'epoch': 100.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "750f02b3-3f81-4aff-9c59-e4b3ce0385db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 38.63\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
